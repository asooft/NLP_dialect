{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WME9EAoI6t9v"
      },
      "source": [
        "# NLP Project (Arabic Dialect Classification)-ML"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XQTCB-J06t92"
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OusXSNjg6t93",
        "outputId": "ae19cf37-80a2-49c4-d254-dfc6dac3712d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ihabn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import emoji\n",
        "import re\n",
        "import tashaphyne.normalize as normalize\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import RidgeClassifier"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oed-1-Bv6t96"
      },
      "source": [
        "### Reading the data and labels files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V82q7GAt6t97",
        "outputId": "442b132a-ff69-41f9-989d-9bf45c6f9f3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>dialect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1009754958479151232</td>\n",
              "      <td>@toha_Altomy @gy_yah ŸÇŸÑŸäŸÑŸäŸÜ ÿßÿØÿ® ŸàŸÖŸÜÿßŸÅŸÇŸäŸÜ. ŸÑŸà ÿß...</td>\n",
              "      <td>LY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1009794751548313600</td>\n",
              "      <td>@AlmFaisal üòÇüòÇ ÿßŸÑŸÑŸäÿ®ŸäŸäŸÜ ŸÖÿ™ŸÇŸÑÿ®ŸäŸÜ!!!\\nÿ®ÿ≥ ÿ®ÿßŸÑŸÜÿ≥ÿ®ÿ© ...</td>\n",
              "      <td>LY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1019989115490787200</td>\n",
              "      <td>@smsm071990 @ALMOGRBE ŸÉŸÑ 20 ÿ™ÿßŸÜŸäŸá ÿ¥ÿßÿ® ŸÑŸäÿ®Ÿä ÿ®Ÿäÿ±...</td>\n",
              "      <td>LY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1035479791758135168</td>\n",
              "      <td>@AboryPro @lyranoo85 ÿ±ÿßŸÜŸäÿß ÿπŸÇŸÑŸäÿ™ŸÉ ŸÖÿ™ÿÆŸÑŸÅÿ©. ÿßŸàŸÑÿß...</td>\n",
              "      <td>LY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1035481122921164800</td>\n",
              "      <td>@lyranoo85 ÿ¥ŸÉŸÑŸÉ ŸÖÿ™ÿπŸÇÿØÿ© ÿπŸÑÿ¥ÿßŸÜ ÿßŸÑÿ±ÿßÿ¨ŸÑ ŸÑŸä ÿ™ÿ≠ÿ®ŸäŸá ÿß...</td>\n",
              "      <td>LY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id                                               text  \\\n",
              "0  1009754958479151232  @toha_Altomy @gy_yah ŸÇŸÑŸäŸÑŸäŸÜ ÿßÿØÿ® ŸàŸÖŸÜÿßŸÅŸÇŸäŸÜ. ŸÑŸà ÿß...   \n",
              "1  1009794751548313600  @AlmFaisal üòÇüòÇ ÿßŸÑŸÑŸäÿ®ŸäŸäŸÜ ŸÖÿ™ŸÇŸÑÿ®ŸäŸÜ!!!\\nÿ®ÿ≥ ÿ®ÿßŸÑŸÜÿ≥ÿ®ÿ© ...   \n",
              "2  1019989115490787200  @smsm071990 @ALMOGRBE ŸÉŸÑ 20 ÿ™ÿßŸÜŸäŸá ÿ¥ÿßÿ® ŸÑŸäÿ®Ÿä ÿ®Ÿäÿ±...   \n",
              "3  1035479791758135168  @AboryPro @lyranoo85 ÿ±ÿßŸÜŸäÿß ÿπŸÇŸÑŸäÿ™ŸÉ ŸÖÿ™ÿÆŸÑŸÅÿ©. ÿßŸàŸÑÿß...   \n",
              "4  1035481122921164800  @lyranoo85 ÿ¥ŸÉŸÑŸÉ ŸÖÿ™ÿπŸÇÿØÿ© ÿπŸÑÿ¥ÿßŸÜ ÿßŸÑÿ±ÿßÿ¨ŸÑ ŸÑŸä ÿ™ÿ≠ÿ®ŸäŸá ÿß...   \n",
              "\n",
              "  dialect  \n",
              "0      LY  \n",
              "1      LY  \n",
              "2      LY  \n",
              "3      LY  \n",
              "4      LY  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1=pd.read_csv(r\"C:\\Users\\ihabn\\id_text.csv\")\n",
        "df2=pd.read_csv(r\"C:\\Users\\ihabn\\id_dialect.csv\")\n",
        "df = pd.merge(df1, df2, on='id')\n",
        "df.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "krNe76Gp6t98"
      },
      "source": [
        "### Our 5 Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RJHdZo_6t99",
        "outputId": "aa8062e9-a7a7-4bfc-f1d5-af0e9823b581"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['LY', 'MA', 'EG', 'LB', 'SD'], dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dialect.unique()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "keyfjpig6t9-"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gnttHgyU6t9_"
      },
      "source": [
        "##### Replace new lines from the data with a space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0YI6pcq6t9_"
      },
      "outputs": [],
      "source": [
        "def replace_newlines(txt):\n",
        "    return txt.replace('\\n', ' ')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6YSZEPW6t-A"
      },
      "source": [
        "##### Removing tags (@user) and any consecutive spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tTi5UeA6t-A"
      },
      "outputs": [],
      "source": [
        "def remove_tag(txt):\n",
        "    return re.sub(r'@\\w+\\s*', '', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vVeJvV4G6t-B"
      },
      "source": [
        "##### Remove links and any consecutive spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v18qiuO26t-B"
      },
      "outputs": [],
      "source": [
        "def remove_links(txt):\n",
        "    return re.sub(r'https?\\S+\\s*', '', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A4AlsmlC6t-C"
      },
      "source": [
        "##### Removing English sentences and any consecutive spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxQ3STby6t-C"
      },
      "outputs": [],
      "source": [
        "def remove_english(txt):\n",
        "    return re.sub(r'[a-zA-Z]+\\s*', '', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4hagQ-NP6t-C"
      },
      "source": [
        "##### Remove all emojies and any consecutive spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2xvATs76t-D"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(txt):\n",
        "    return emoji.replace_emoji(txt, '')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe0-qef16t-D"
      },
      "source": [
        "##### Remove unuseful marks <br>( These marks can be used for old style emojis )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4i9F28p6t-E"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(txt):\n",
        "    return re.sub(r'[^\\w\\s]|[_]', '', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hSHcOWbt6t-E"
      },
      "source": [
        "##### Normalize laughter sounds (\"ŸáŸáŸá\", \"ŸáŸáŸáŸá\") to a single instance (\"ŸáŸá\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1Pc2OPy6t-F"
      },
      "outputs": [],
      "source": [
        "def map_laughter(txt):\n",
        "    return re.sub(r'(ŸáŸá)Ÿá+', 'ŸáŸá', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fxuYCEuq6t-G"
      },
      "source": [
        "##### Remove repeated letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxsmtQyP6t-G"
      },
      "outputs": [],
      "source": [
        "def remove_repeated_letters(txt):\n",
        "    return re.sub(r'(.)\\1{2,}', r'\\1', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n9arIUvt6t-G"
      },
      "source": [
        "##### Remove numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRdu8Nbh6t-H"
      },
      "outputs": [],
      "source": [
        "def remove_numbers(txt):\n",
        "    return re.sub(r'\\d+', '', txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vinkzGdG6t-H"
      },
      "source": [
        "##### Character normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsdelZZH6t-H"
      },
      "outputs": [],
      "source": [
        "def normalize_arabic(txt):\n",
        "    return normalize.normalize_searchtext(txt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V91U_Hg36t-I"
      },
      "source": [
        "##### Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsziYLwI6t-I"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(txt, stop_words):\n",
        "    return \" \".join([word for word in word_tokenize(txt) if word not in stop_words])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LrwZU4of6t-I"
      },
      "source": [
        "##### Remove repeated spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAdCMxYV6t-J"
      },
      "outputs": [],
      "source": [
        "def remove_repeated_spaces(txt):\n",
        "    return re.sub(r'\\s{2,}', ' ', txt).strip()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3cJHzljd6t-J"
      },
      "source": [
        "# Preprocessing function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uv4eUox6t-J"
      },
      "outputs": [],
      "source": [
        "def Preprocessing(text):\n",
        "    text = replace_newlines(text)\n",
        "    text = remove_tag(text)\n",
        "    text = remove_links(text)\n",
        "    text = remove_english(text)\n",
        "    text = remove_emoji(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = map_laughter(text)\n",
        "    text = normalize_arabic(text)\n",
        "    text = remove_repeated_letters(text)\n",
        "    text = remove_numbers(text)\n",
        "    ar_stop_words = set(stopwords.words('arabic'))\n",
        "    ar_stop_words = [normalize_arabic(word) for word in ar_stop_words]\n",
        "    text = remove_stop_words(text,ar_stop_words)\n",
        "    text = remove_repeated_spaces(text)\n",
        "    return text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VVSlQ1by6t-K"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlFKeU706t-K"
      },
      "outputs": [],
      "source": [
        "df.dialect= df.dialect.replace({'EG': 1,\n",
        "                                        'LY': 2,\n",
        "                                        'LB': 3,\n",
        "                                        'SD': 4,\n",
        "                                        'MA': 5\n",
        "                                        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2CtVZbI6t-K"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'dialect': 'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPAASzHx6t-K"
      },
      "outputs": [],
      "source": [
        "X = df['text']\n",
        "y = df['label']\n",
        "t_size = 0.20\n",
        "random_state = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=random_state,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_KcleIl6t-L",
        "outputId": "1de36145-6c8c-4669-b9dc-5a95c94d770b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (118180,) (118180,)\n",
            "Test shape: (29545,) (29545,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stYPtPSC6t-L",
        "outputId": "96cb3070-df2f-4de6-a996-0479b8cfd1fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 0.39052293112201725,\n",
              " 2: 0.2473430360467084,\n",
              " 3: 0.18648671518023355,\n",
              " 4: 0.0973261127094263,\n",
              " 5: 0.07832120494161449}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sumall = y_train.count()\n",
        "classes, counts = np.unique(y_train, return_counts=True)\n",
        "wei = counts / sumall\n",
        "class_weights_dict = {}\n",
        "for i in range(1, 6):\n",
        "    weight = counts[i-1] / sumall\n",
        "    class_weights_dict[i] = weight\n",
        "class_weights_dict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TcDom9Ov6t-L"
      },
      "source": [
        "# pipeLine with different classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfajBxvN6t-M",
        "outputId": "a6ed7750-2218-42ab-f3a0-e8284ad278ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        accuracy_test  precision_test  recall_test  \\\n",
            "LogisticRegression              69.74           84.25        51.93   \n",
            "MultinomialNB                   72.13           87.56        56.09   \n",
            "LinearSVC                       81.06           85.42        72.30   \n",
            "RandomForestClassifier          73.69           78.69        63.04   \n",
            "\n",
            "                        f1_test-score  \n",
            "LogisticRegression              54.29  \n",
            "MultinomialNB                   60.12  \n",
            "LinearSVC                       76.51  \n",
            "RandomForestClassifier          67.34  \n"
          ]
        }
      ],
      "source": [
        "class PreprocessingClass(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [Preprocessing(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "classifiers = {\n",
        "    'LogisticRegression': LogisticRegression(class_weight=class_weights_dict, max_iter=1000),\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'LinearSVC': LinearSVC(class_weight=class_weights_dict,max_iter=1000),\n",
        "    'RandomForestClassifier': RandomForestClassifier(class_weight=class_weights_dict)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "pipeline_dict = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessing', PreprocessingClass()),\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', clf)\n",
        "    ])\n",
        "\n",
        "    # Fit the pipeline on the training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluate the performance on the test set\n",
        "    report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
        "    accuracy_test = round(report_test['accuracy'] * 100, 2)\n",
        "    precision_test = round(report_test['macro avg']['precision'] * 100, 2)\n",
        "    recall_test = round(report_test['macro avg']['recall'] * 100, 2)\n",
        "    f1_test = round(report_test['macro avg']['f1-score'] * 100, 2)\n",
        "    results[name] = {\n",
        "        'accuracy_test': accuracy_test,\n",
        "        'precision_test': precision_test,\n",
        "        'recall_test': recall_test,\n",
        "        'f1_test-score': f1_test\n",
        "    }\n",
        "    pipeline_dict[name] = {\n",
        "        'Report_test': report_test,\n",
        "        'pipeline': pipeline,\n",
        "        'y_pred_test': y_pred_test\n",
        "    }\n",
        "\n",
        "df_Result = pd.DataFrame(results).transpose()\n",
        "print(df_Result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMlWzrU86t-M",
        "outputId": "ed1c0f76-52e0-4f02-cc55-23f38c0ff34e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_test</th>\n",
              "      <th>precision_test</th>\n",
              "      <th>recall_test</th>\n",
              "      <th>f1_test-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>69.74</td>\n",
              "      <td>84.25</td>\n",
              "      <td>51.93</td>\n",
              "      <td>54.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>72.13</td>\n",
              "      <td>87.56</td>\n",
              "      <td>56.09</td>\n",
              "      <td>60.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>81.06</td>\n",
              "      <td>85.42</td>\n",
              "      <td>72.30</td>\n",
              "      <td>76.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>73.69</td>\n",
              "      <td>78.69</td>\n",
              "      <td>63.04</td>\n",
              "      <td>67.34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        accuracy_test  precision_test  recall_test  \\\n",
              "LogisticRegression              69.74           84.25        51.93   \n",
              "MultinomialNB                   72.13           87.56        56.09   \n",
              "LinearSVC                       81.06           85.42        72.30   \n",
              "RandomForestClassifier          73.69           78.69        63.04   \n",
              "\n",
              "                        f1_test-score  \n",
              "LogisticRegression              54.29  \n",
              "MultinomialNB                   60.12  \n",
              "LinearSVC                       76.51  \n",
              "RandomForestClassifier          67.34  "
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_Result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "158fZaP16t-N"
      },
      "source": [
        "# Linear SVC and Ridge classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MctLNmqK6t-N",
        "outputId": "0816bc1a-9e5f-434d-b4ab-b1322f554ead"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_test</th>\n",
              "      <th>precision_test</th>\n",
              "      <th>recall_test</th>\n",
              "      <th>f1_test-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>81.06</td>\n",
              "      <td>85.42</td>\n",
              "      <td>72.30</td>\n",
              "      <td>76.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>74.93</td>\n",
              "      <td>85.97</td>\n",
              "      <td>61.03</td>\n",
              "      <td>65.91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           accuracy_test  precision_test  recall_test  f1_test-score\n",
              "LinearSVC          81.06           85.42        72.30          76.51\n",
              "Ridge              74.93           85.97        61.03          65.91"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class PreprocessingClass(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [Preprocessing(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "\n",
        "classifiers = {\n",
        "    'LinearSVC': LinearSVC(class_weight=class_weights_dict, max_iter=1000),\n",
        "    'Ridge': RidgeClassifier(class_weight=class_weights_dict)\n",
        "}\n",
        "    \n",
        "\n",
        "\n",
        "results = {}\n",
        "pipeline_dict = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessing', PreprocessingClass()),\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', clf)\n",
        "    ])\n",
        "\n",
        "    # Fit the pipeline on the training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluate the performance on the test set\n",
        "    report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
        "    accuracy_test = round(report_test['accuracy'] * 100, 2)\n",
        "    precision_test = round(report_test['macro avg']['precision'] * 100, 2)\n",
        "    recall_test = round(report_test['macro avg']['recall'] * 100, 2)\n",
        "    f1_test = round(report_test['macro avg']['f1-score'] * 100, 2)\n",
        "    results[name] = {\n",
        "        'accuracy_test': accuracy_test,\n",
        "        'precision_test': precision_test,\n",
        "        'recall_test': recall_test,\n",
        "        'f1_test-score': f1_test\n",
        "    }\n",
        "    pipeline_dict[name] = {\n",
        "        'Report_test': report_test,\n",
        "        'pipeline': pipeline,\n",
        "        'y_pred_test': y_pred_test\n",
        "    }\n",
        "\n",
        "df_Result = pd.DataFrame(results).transpose()\n",
        "df_Result\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GS9mZQai64UK"
      },
      "source": [
        "## **Mazaj Vectorizer with Linear SVC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl91ztbopgNv",
        "outputId": "0a485469-6a6f-4225-f79d-ecf6e7a817d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           accuracy_test  f1_test-score  precision_test  recall_test\n",
            "LinearSVC          77.61          72.23           77.51        69.44\n"
          ]
        }
      ],
      "source": [
        "class PreprocessingClass(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [Preprocessing(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class WordEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, embedding_model, max_sequence_length):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "\n",
        "    def transform(self, X, **transform_params):\n",
        "        embedded_X = []\n",
        "        for text in X:\n",
        "            embedded_text = []\n",
        "            for word in text.split():\n",
        "                if word in self.embedding_model:\n",
        "                    embedded_text.append(self.embedding_model[word])\n",
        "                else:\n",
        "                    embedded_text.append([0.0] * self.embedding_model.vector_size)\n",
        "            embedded_X.append(embedded_text)\n",
        "\n",
        "        # Pad or truncate the sequences to a fixed length\n",
        "        padded_X = self._pad_sequences(embedded_X)\n",
        "\n",
        "        return np.stack(padded_X)\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def _pad_sequences(self, sequences):\n",
        "        padded_sequences = []\n",
        "        for seq in sequences:\n",
        "            if len(seq) < self.max_sequence_length:\n",
        "                # Pad sequence with zeros\n",
        "                padded_seq = seq + [[0.0] * self.embedding_model.vector_size] * (self.max_sequence_length - len(seq))\n",
        "            else:\n",
        "                # Truncate sequence to the maximum length\n",
        "                padded_seq = seq[:self.max_sequence_length]\n",
        "            padded_sequences.append(padded_seq)\n",
        "        return padded_sequences\n",
        "\n",
        "\n",
        "class FlattenTransformer(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return X.reshape(X.shape[0], -1)\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "\n",
        "classifiers = {\n",
        "    'LinearSVC': LinearSVC(class_weight=class_weights_dict)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "pipeline_dict = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessing', PreprocessingClass()),\n",
        "        ('embedding', WordEmbeddingTransformer(mazajak_model,20)),\n",
        "        ('flatten', FlattenTransformer()),\n",
        "        ('clf', clf)\n",
        "    ])\n",
        "    # Fit the pipeline on the training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluate the performance on the test set\n",
        "    report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
        "    accuracy_test = round(report_test['accuracy'] * 100, 2)\n",
        "    precision_test = round(report_test['macro avg']['precision'] * 100, 2)\n",
        "    recall_test = round(report_test['macro avg']['recall'] * 100, 2)\n",
        "    f1_test = round(report_test['macro avg']['f1-score'] * 100, 2)\n",
        "    results[name] = {\n",
        "        'accuracy_test': accuracy_test,\n",
        "        'precision_test': precision_test,\n",
        "        'recall_test': recall_test,\n",
        "        'f1_test-score': f1_test\n",
        "    }\n",
        "    pipeline_dict[name] = {\n",
        "        'Report_test': report_test,\n",
        "        'pipeline': pipeline,\n",
        "        'y_pred_test': y_pred_test\n",
        "    }\n",
        "\n",
        "df_Result = pd.DataFrame(results).transpose()\n",
        "print(df_Result)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F3nDdQT-7ebN"
      },
      "source": [
        "## `From Results we selected Linear SVC with TF-IDF vectorizer`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vg8tnaFY6t-O"
      },
      "source": [
        "# Linear SVC Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvC8VcHn6t-O",
        "outputId": "41b2dc9b-2fee-4b00-8493-e838517b6c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.78      0.94      0.85     11484\n",
            "          LB       0.79      0.81      0.80      7268\n",
            "          LY       0.86      0.81      0.84      5578\n",
            "          MA       0.90      0.48      0.62      2932\n",
            "          SD       0.94      0.57      0.71      2283\n",
            "\n",
            "    accuracy                           0.81     29545\n",
            "   macro avg       0.85      0.72      0.77     29545\n",
            "weighted avg       0.82      0.81      0.80     29545\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class_names = ['EG', 'LB', 'LY', 'MA', 'SD']\n",
        "# Evaluate the pipeline on the test data\n",
        "y_pred = pipeline_dict['LinearSVC']['pipeline'].predict(X_test)\n",
        "report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BMUlOEIO6t-P"
      },
      "source": [
        "#### Test Model random Scentences(showing the original scentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyFZJxCy6t-P",
        "outputId": "ae4ad96b-9d31-4058-8bcf-45d96fa581bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random sentence: @aliimortada @amer__h üòèüòèüòèüòèüòè ŸÑŸäŸá ŸÉÿ±ŸÖÿßŸÑ ŸÜÿ®ÿ∑ŸÑ ÿ±ÿπÿßÿπ\n",
            "True label: 3\n",
            "Predicted label: 3\n",
            "------------------------\n",
            "Random sentence: @beINSPORTS_news Ÿäÿ±Ÿäÿ™ ÿ™ÿ≠ŸàŸÑŸà ÿßŸÑÿ¥ÿ±Ÿäÿ∑ ÿßŸÑÿßÿ≠ŸÖÿ± ŸäŸÑŸä Ÿäÿ∑ŸÑÿπ ŸÉŸÑ ÿ¥ŸàŸäŸá ŸÉÿ±Ÿáÿ™ŸàŸÜÿß ŸÅŸä ÿßŸÑŸÉŸàÿ±Ÿá ÿ¨ÿØÿØŸÜÿß ÿ®ÿ´ŸÖŸÜ ÿ∫ÿßŸÑŸä Ÿà ÿßŸÑŸÖÿπŸÑŸÇŸäŸÜ Ÿäÿ≠ŸÉŸà ÿπŸÑŸä ÿßŸÑÿ≥ÿ±ŸÇŸá ŸÖÿπÿ¥ ŸäÿπŸÑŸÇŸà ÿπÿßŸÑŸÖÿ®ÿßÿ±ÿßŸá .ŸàÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ\n",
            "True label: 2\n",
            "Predicted label: 2\n",
            "------------------------\n",
            "Random sentence: @ahmedyassine30 @FatimahGhamlush üòÖüòÖ ÿ®ÿ∫Ÿäÿ®ÿ™ŸÉ ÿπŸÖ ŸÜÿØŸäÿ± ÿ®ÿßŸÑŸÜÿß ÿπÿßŸÑÿ≠ÿ®ÿßŸäÿ® üò∂\n",
            "True label: 3\n",
            "Predicted label: 3\n",
            "------------------------\n",
            "Random sentence: ŸÇŸàŸÑÿ™ŸàŸÑŸä ÿßŸÑÿ£ŸàŸÑÿ™ÿ±ÿßÿ≥ ŸÉÿßŸÜŸàÿß ÿ®ŸäÿÆŸÑÿ∑Ÿàÿß ÿßŸÑŸÉŸàÿ±ÿ© ÿ®ÿßŸÑÿ≥Ÿäÿßÿ≥ÿ© ŸÖÿ¥ ŸÉÿØŸá ... \n",
            "\n",
            "üòÇüòÇüòÇüòÇ https://t.co/pXxIrQkIns\n",
            "True label: 1\n",
            "Predicted label: 1\n",
            "------------------------\n",
            "Random sentence: ŸáŸà ÿØŸá \n",
            " ŸáŸà ÿØŸá \n",
            "ŸáŸà ÿØŸá ÿßŸÑÿ≠ÿ∂ŸÜ ÿßŸÑÿ≠ŸÇŸäŸÇŸâ https://t.co/cnPbnzWbHa\n",
            "True label: 2\n",
            "Predicted label: 1\n",
            "------------------------\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "def evaluate_random_sentences(pipeline, X_test, y_test, num_sentences):\n",
        "    random_indices = random.sample(range(len(X_test)), num_sentences)\n",
        "    random_sentences = X_test.iloc[random_indices]  \n",
        "    true_labels = y_test.iloc[random_indices]  \n",
        "    predicted_labels = pipeline.predict(random_sentences)\n",
        "\n",
        "    for i in range(num_sentences):\n",
        "        print(\"Random sentence:\", random_sentences.iloc[i])\n",
        "        print(\"True label:\", true_labels.iloc[i])\n",
        "        print(\"Predicted label:\", predicted_labels[i])\n",
        "        print(\"------------------------\")\n",
        "\n",
        "num_sentences = 5  \n",
        "evaluate_random_sentences(pipeline, X_test, y_test, num_sentences)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RgXMRgpo6t-P"
      },
      "source": [
        "# PipeLine Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CISH6_ri6t-Q",
        "outputId": "a6337d01-627b-4a67-f547-c74bd396faf4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 &lt;__main__.PreprocessingClass object at 0x000002431BB046A0&gt;),\n",
              "                (&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 LinearSVC(class_weight={1: 0.39052293112201725,\n",
              "                                         2: 0.2473430360467084,\n",
              "                                         3: 0.18648671518023355,\n",
              "                                         4: 0.0973261127094263,\n",
              "                                         5: 0.07832120494161449}))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 &lt;__main__.PreprocessingClass object at 0x000002431BB046A0&gt;),\n",
              "                (&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 LinearSVC(class_weight={1: 0.39052293112201725,\n",
              "                                         2: 0.2473430360467084,\n",
              "                                         3: 0.18648671518023355,\n",
              "                                         4: 0.0973261127094263,\n",
              "                                         5: 0.07832120494161449}))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PreprocessingClass</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.PreprocessingClass object at 0x000002431BB046A0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(class_weight={1: 0.39052293112201725, 2: 0.2473430360467084,\n",
              "                        3: 0.18648671518023355, 4: 0.0973261127094263,\n",
              "                        5: 0.07832120494161449})</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessing',\n",
              "                 <__main__.PreprocessingClass object at 0x000002431BB046A0>),\n",
              "                ('tfidf', TfidfVectorizer()),\n",
              "                ('clf',\n",
              "                 LinearSVC(class_weight={1: 0.39052293112201725,\n",
              "                                         2: 0.2473430360467084,\n",
              "                                         3: 0.18648671518023355,\n",
              "                                         4: 0.0973261127094263,\n",
              "                                         5: 0.07832120494161449}))])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_dict['LinearSVC']['pipeline']\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e-L4ZCmN6t-Q"
      },
      "source": [
        "# Saving The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QsdXkz76t-Q",
        "outputId": "e010650b-8a25-4fa6-c66b-9d430f100bc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model1.pkl']"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(pipeline_dict['LinearSVC']['pipeline'], 'model1.pkl')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x3bK0W8u6t-R"
      },
      "source": [
        "# Loading The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAmLJmBI6t-R"
      },
      "outputs": [],
      "source": [
        "loaded_pipeline = joblib.load('model1.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
